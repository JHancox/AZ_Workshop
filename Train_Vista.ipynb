{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c24c3-d04d-436a-ae7f-f8048dd6f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fast remap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65713b-d532-4285-8926-2e99074bd47a",
   "metadata": {},
   "source": [
    "python -m monai.bundle run_workflow \"scripts.workflow.VistaCell\" --config_file configs/hyper_parameters.yaml\n",
    "\n",
    "Whilst you can simply run a script, we are going to break things down a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416b456d-c6e5-4599-a571-7ad02c6198ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cell_distributed_weighted_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m mlflow, mlflow_is_imported \u001b[38;5;241m=\u001b[39m optional_import(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __package__ \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcell_distributed_weighted_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedWeightedSampler\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelsToFlows, LoadTiffd, LogitsToLabels\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOGGING_CONFIG, parsing_bundle_config  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cell_distributed_weighted_sampler'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import csv\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import monai.transforms as mt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import yaml\n",
    "from monai.apps import get_logger\n",
    "from monai.auto3dseg.utils import datafold_read\n",
    "from monai.bundle import BundleWorkflow, ConfigParser\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from monai.metrics import CumulativeAverage\n",
    "from monai.utils import (\n",
    "    BundleProperty,\n",
    "    ImageMetaKey,\n",
    "    convert_to_dst_type,\n",
    "    ensure_tuple,\n",
    "    look_up_option,\n",
    "    optional_import,\n",
    "    set_determinism,\n",
    ")\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "mlflow, mlflow_is_imported = optional_import(\"mlflow\")\n",
    "\n",
    "\n",
    "if __package__ in (None, \"\"):\n",
    "    from cell_distributed_weighted_sampler import DistributedWeightedSampler\n",
    "    from components import LabelsToFlows, LoadTiffd, LogitsToLabels\n",
    "    from utils import LOGGING_CONFIG, parsing_bundle_config  # type: ignore\n",
    "else:\n",
    "    from .cell_distributed_weighted_sampler import DistributedWeightedSampler\n",
    "    from .components import LabelsToFlows, LoadTiffd, LogitsToLabels\n",
    "    from .utils import LOGGING_CONFIG, parsing_bundle_config\n",
    "\n",
    "\n",
    "logger = get_logger(\"VistaCell\")\n",
    "\n",
    "\n",
    "class VistaCell(BundleWorkflow):\n",
    "    \"\"\"\n",
    "    Primary vista model training workflow that extends\n",
    "    monai.bundle.BundleWorkflow for cell segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file=None,\n",
    "        meta_file=None,\n",
    "        logging_file=None,\n",
    "        workflow_type=\"train\",\n",
    "        **override,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        config_file can be one or a list of config files.\n",
    "        the rest key-values in the `override` are to override config content.\n",
    "        \"\"\"\n",
    "\n",
    "        parser = parsing_bundle_config(\n",
    "            config_file, logging_file=logging_file, meta_file=meta_file\n",
    "        )\n",
    "        parser.update(pairs=override)\n",
    "\n",
    "        mode = parser.get(\"mode\", None)\n",
    "        if (\n",
    "            mode is not None\n",
    "        ):  # if user specified a `mode` it'll override the workflow_type arg\n",
    "            workflow_type = mode\n",
    "        else:\n",
    "            mode = workflow_type  # if user didn't specify mode, the workflow_type will be used\n",
    "        super().__init__(workflow_type=workflow_type)\n",
    "        self._props = {}\n",
    "        self._set_props = {}\n",
    "        self.parser = parser\n",
    "\n",
    "        self.rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "        self.global_rank = int(os.getenv(\"RANK\", \"0\"))\n",
    "        self.is_distributed = dist.is_available() and dist.is_initialized()\n",
    "\n",
    "        # check if torchrun or bcprun started it\n",
    "        if dist.is_torchelastic_launched() or (\n",
    "            os.getenv(\"NGC_ARRAY_SIZE\") is not None\n",
    "            and int(os.getenv(\"NGC_ARRAY_SIZE\")) > 1\n",
    "        ):\n",
    "            if dist.is_available():\n",
    "                dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "\n",
    "            self.is_distributed = dist.is_available() and dist.is_initialized()\n",
    "\n",
    "            torch.cuda.set_device(self.config(\"device\"))\n",
    "            dist.barrier()\n",
    "\n",
    "        else:\n",
    "            self.is_distributed = False\n",
    "\n",
    "        if (\n",
    "            self.global_rank == 0\n",
    "            and self.config(\"ckpt_path\")\n",
    "            and not os.path.exists(self.config(\"ckpt_path\"))\n",
    "        ):\n",
    "            os.makedirs(self.config(\"ckpt_path\"), exist_ok=True)\n",
    "\n",
    "        if self.rank == 0:\n",
    "            # make sure the log file exists, as a workaround for mult-gpu logging race condition\n",
    "            _log_file = self.config(\"log_output_file\", \"vista_cell.log\")\n",
    "            if _log_file is not None:\n",
    "                open(_log_file, \"a\").close()\n",
    "\n",
    "            print_config()\n",
    "\n",
    "        if self.is_distributed:\n",
    "            dist.barrier()\n",
    "\n",
    "        seed = self.config(\"seed\", None)\n",
    "        if seed is not None:\n",
    "            set_determinism(seed)\n",
    "            logger.info(f\"set determinism seed: {self.config('seed', None)}\")\n",
    "        elif torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            logger.info(\"No seed provided, using cudnn.benchmark for performance.\")\n",
    "\n",
    "        if os.path.exists(self.config(\"ckpt_path\")):\n",
    "            self.parser.export_config_file(\n",
    "                self.parser.config,\n",
    "                os.path.join(self.config(\"ckpt_path\"), \"working.yaml\"),\n",
    "                fmt=\"yaml\",\n",
    "                default_flow_style=None,\n",
    "            )\n",
    "\n",
    "        self.add_property(\"network\", required=True)\n",
    "        self.add_property(\"train_loader\", required=True)\n",
    "        self.add_property(\"val_dataset\", required=False)\n",
    "        self.add_property(\"val_loader\", required=False)\n",
    "        self.add_property(\"val_preprocessing\", required=False)\n",
    "        self.add_property(\"train_sampler\", required=True)\n",
    "        self.add_property(\"val_sampler\", required=True)\n",
    "        self.add_property(\"mode\", required=False)\n",
    "        # set evaluator as required when mode is infer or eval\n",
    "        # will change after we enhance the bundle properties\n",
    "        self.evaluator = None\n",
    "\n",
    "    def _set_property(self, name, property, value):\n",
    "        # stores user-reset initialized objects that should not be re-initialized.\n",
    "        self._set_props[name] = value\n",
    "\n",
    "    def _get_property(self, name, property):\n",
    "        \"\"\"\n",
    "        The customized bundle workflow must implement required properties in:\n",
    "        https://github.com/Project-MONAI/MONAI/blob/dev/monai/bundle/properties.py.\n",
    "        \"\"\"\n",
    "        if name in self._set_props:\n",
    "            self._props[name] = self._set_props[name]\n",
    "            return self._props[name]\n",
    "        if name in self._props:\n",
    "            return self._props[name]\n",
    "        try:\n",
    "            value = getattr(self, f\"get_{name}\")()\n",
    "        except AttributeError:\n",
    "            if property[BundleProperty.REQUIRED]:\n",
    "                raise ValueError(\n",
    "                    f\"Property '{name}' is required by the bundle format,\"\n",
    "                    f\"but the method 'get_{name}' is not implemented.\"\n",
    "                )\n",
    "            raise AttributeError\n",
    "        self._props[name] = value\n",
    "        return value\n",
    "\n",
    "    def config(self, name, default=\"null\", **kwargs):\n",
    "        \"\"\"read the parsed content (evaluate the expression) from the config file.\"\"\"\n",
    "        if default != \"null\":\n",
    "            return self.parser.get_parsed_content(name, default=default, **kwargs)\n",
    "        return self.parser.get_parsed_content(name, **kwargs)\n",
    "\n",
    "    def initialize(self):\n",
    "        _log_file = self.config(\"log_output_file\", \"vista_cell.log\")\n",
    "        if _log_file is None:\n",
    "            LOGGING_CONFIG[\"loggers\"][\"VistaCell\"][\"handlers\"].remove(\"file\")\n",
    "            LOGGING_CONFIG[\"handlers\"].pop(\"file\", None)\n",
    "        else:\n",
    "            LOGGING_CONFIG[\"handlers\"][\"file\"][\"filename\"] = _log_file\n",
    "        logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "    def get_mode(self):\n",
    "        mode_str = self.config(\"mode\", self.workflow_type)\n",
    "        return look_up_option(\n",
    "            mode_str, (\"train\", \"training\", \"infer\", \"inference\", \"eval\", \"evaluation\")\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        if str(self.mode).startswith(\"train\"):\n",
    "            return self.train()\n",
    "        if str(self.mode).startswith(\"infer\"):\n",
    "            return self.infer()\n",
    "        return self.validate()\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.is_distributed:\n",
    "            dist.destroy_process_group()\n",
    "        set_determinism(None)\n",
    "\n",
    "    def get_network_def(self):\n",
    "        return self.config(\"network_def\")\n",
    "\n",
    "    def get_network(self):\n",
    "        pretrained_ckpt_name = self.config(\"pretrained_ckpt_name\", None)\n",
    "        pretrained_ckpt_path = self.config(\"pretrained_ckpt_path\", None)\n",
    "        if pretrained_ckpt_name is not None and pretrained_ckpt_path is None:\n",
    "            # if relative name specified, append to default ckpt_path dir\n",
    "            pretrained_ckpt_path = os.path.join(\n",
    "                self.config(\"ckpt_path\"), pretrained_ckpt_name\n",
    "            )\n",
    "\n",
    "        if pretrained_ckpt_path is not None and not os.path.exists(\n",
    "            pretrained_ckpt_path\n",
    "        ):\n",
    "            logger.info(f\"Pretrained checkpoint {pretrained_ckpt_path} not found.\")\n",
    "            raise ValueError(f\"Pretrained checkpoint {pretrained_ckpt_path} not found.\")\n",
    "\n",
    "        if pretrained_ckpt_path is not None and os.path.exists(pretrained_ckpt_path):\n",
    "            # not loading sam weights, if we're using our own checkpoint\n",
    "            if \"checkpoint\" in self.parser.config[\"network_def\"]:\n",
    "                self.parser.config[\"network_def\"][\"checkpoint\"] = None\n",
    "            model = self.config(\"network\")\n",
    "            self.checkpoint_load(ckpt=pretrained_ckpt_path, model=model)\n",
    "        else:\n",
    "            model = self.config(\"network\")\n",
    "\n",
    "        if self.config(\"channels_last\", False):\n",
    "            model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "        if self.is_distributed:\n",
    "            model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "        if self.config(\"compile\", False):\n",
    "            model = torch.compile(model)\n",
    "\n",
    "        if self.is_distributed:\n",
    "            model = torch.nn.parallel.DistributedDataParallel(\n",
    "                module=model,\n",
    "                device_ids=[self.rank],\n",
    "                output_device=self.rank,\n",
    "                find_unused_parameters=self.config(\"find_unused_parameters\", False),\n",
    "            )\n",
    "\n",
    "        pytorch_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(\n",
    "            f\"total parameters count {pytorch_params} distributed {self.is_distributed}\"\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def get_train_dataset_data(self):\n",
    "        train_files, valid_files = [], []\n",
    "        dataset_data = self.config(\"train#dataset#data\")\n",
    "        val_key = None\n",
    "        if isinstance(dataset_data, dict):\n",
    "            val_key = dataset_data.get(\"key\", None)\n",
    "        data_list_files = dataset_data[\"data_list_files\"]\n",
    "\n",
    "        if isinstance(data_list_files, str):\n",
    "            data_list_files = ConfigParser.load_config_file(\n",
    "                data_list_files\n",
    "            )  # if it's a path to a separate file with a list of datasets\n",
    "        else:\n",
    "            data_list_files = ensure_tuple(data_list_files)\n",
    "\n",
    "        if self.global_rank == 0:\n",
    "            print(\"Using data_list_files \", data_list_files)\n",
    "\n",
    "        for idx, d in enumerate(data_list_files):\n",
    "            logger.info(f\"adding datalist ({idx}): {d['datalist']}\")\n",
    "            t, v = datafold_read(\n",
    "                datalist=d[\"datalist\"], basedir=d[\"basedir\"], fold=self.config(\"fold\")\n",
    "            )\n",
    "\n",
    "            if val_key is not None:\n",
    "                v, _ = datafold_read(\n",
    "                    datalist=d[\"datalist\"], basedir=d[\"basedir\"], fold=-1, key=val_key\n",
    "                )  # e.g. testing\n",
    "\n",
    "            for item in t:\n",
    "                item[\"datalist_id\"] = idx\n",
    "                item[\"datalist_count\"] = len(t)\n",
    "            for item in v:\n",
    "                item[\"datalist_id\"] = idx\n",
    "                item[\"datalist_count\"] = len(v)\n",
    "            train_files.extend(t)\n",
    "            valid_files.extend(v)\n",
    "\n",
    "        if self.config(\"quick\", False):\n",
    "            logger.info(\"quick_data\")\n",
    "            train_files = train_files[:8]\n",
    "            valid_files = valid_files[:7]\n",
    "        if not valid_files:\n",
    "            logger.warning(\"No validation data found.\")\n",
    "        return train_files, valid_files\n",
    "\n",
    "    def read_val_datalists(\n",
    "        self, section=\"validate\", data_list_files=None, val_key=None, merge=True\n",
    "    ):\n",
    "        \"\"\"read the corresponding folds of the datalist for validation or inference\"\"\"\n",
    "        dataset_data = self.config(f\"{section}#dataset#data\")\n",
    "\n",
    "        if isinstance(dataset_data, list):\n",
    "            return dataset_data\n",
    "\n",
    "        if data_list_files is None:\n",
    "            data_list_files = dataset_data[\"data_list_files\"]\n",
    "\n",
    "        if isinstance(data_list_files, str):\n",
    "            data_list_files = ConfigParser.load_config_file(\n",
    "                data_list_files\n",
    "            )  # if it's a path to a separate file with a list of datasets\n",
    "        else:\n",
    "            data_list_files = ensure_tuple(data_list_files)\n",
    "\n",
    "        if val_key is None:\n",
    "            val_key = dataset_data.get(\"key\", None)\n",
    "\n",
    "        val_files, idx = [], 0\n",
    "        for d in data_list_files:\n",
    "            if val_key is not None:\n",
    "                v_files, _ = datafold_read(\n",
    "                    datalist=d[\"datalist\"], basedir=d[\"basedir\"], fold=-1, key=val_key\n",
    "                )\n",
    "            else:\n",
    "                _, v_files = datafold_read(\n",
    "                    datalist=d[\"datalist\"],\n",
    "                    basedir=d[\"basedir\"],\n",
    "                    fold=self.config(\"fold\"),\n",
    "                )\n",
    "            logger.info(\n",
    "                f\"adding datalist ({idx} -- {val_key}): {d['datalist']} {len(v_files)}\"\n",
    "            )\n",
    "            if merge:\n",
    "                val_files.extend(v_files)\n",
    "            else:\n",
    "                val_files.append(v_files)\n",
    "            idx += 1\n",
    "\n",
    "        if self.config(\"quick\", False):\n",
    "            logger.info(\"quick_data\")\n",
    "            val_files = val_files[:8] if merge else [val_files[0][:8]]\n",
    "        return val_files\n",
    "\n",
    "    def get_train_preprocessing(self):\n",
    "        roi_size = self.config(\"train#dataset#preprocessing#roi_size\")\n",
    "\n",
    "        train_xforms = []\n",
    "        train_xforms.append(LoadTiffd(keys=[\"image\", \"label\"]))\n",
    "        train_xforms.append(\n",
    "            mt.EnsureTyped(\n",
    "                keys=[\"image\", \"label\"], data_type=\"tensor\", dtype=torch.float\n",
    "            )\n",
    "        )\n",
    "        if self.config(\"prescale\", True):\n",
    "            print(\"Prescaling images to 0..1\")\n",
    "            train_xforms.append(\n",
    "                mt.ScaleIntensityd(keys=\"image\", minv=0, maxv=1, channel_wise=True)\n",
    "            )\n",
    "        train_xforms.append(\n",
    "            mt.ScaleIntensityd(keys=\"image\", minv=0, maxv=1, channel_wise=True)\n",
    "        )\n",
    "        train_xforms.append(\n",
    "            mt.ScaleIntensityRangePercentilesd(\n",
    "                keys=\"image\",\n",
    "                lower=1,\n",
    "                upper=99,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                channel_wise=True,\n",
    "                clip=True,\n",
    "            )\n",
    "        )\n",
    "        train_xforms.append(\n",
    "            mt.SpatialPadd(keys=[\"image\", \"label\"], spatial_size=roi_size)\n",
    "        )\n",
    "        train_xforms.append(\n",
    "            mt.RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=roi_size)\n",
    "        )  # crop roi_size (if image is large)\n",
    "\n",
    "        # # add augmentations\n",
    "        train_xforms.extend(\n",
    "            [\n",
    "                mt.RandAffined(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    prob=0.5,\n",
    "                    rotate_range=np.pi,  # from -pi to pi\n",
    "                    scale_range=[-0.5, 0.5],  # from 0.5 to 1.5\n",
    "                    mode=[\"bilinear\", \"nearest\"],\n",
    "                    spatial_size=roi_size,\n",
    "                    cache_grid=True,\n",
    "                    padding_mode=\"border\",\n",
    "                ),\n",
    "                mt.RandAxisFlipd(keys=[\"image\", \"label\"], prob=0.5),\n",
    "                mt.RandGaussianNoised(keys=[\"image\"], prob=0.25, mean=0, std=0.1),\n",
    "                mt.RandAdjustContrastd(keys=[\"image\"], prob=0.25, gamma=(1, 2)),\n",
    "                mt.RandGaussianSmoothd(keys=[\"image\"], prob=0.25, sigma_x=(1, 2)),\n",
    "                mt.RandHistogramShiftd(keys=[\"image\"], prob=0.25, num_control_points=3),\n",
    "                mt.RandGaussianSharpend(keys=[\"image\"], prob=0.25),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        train_xforms.append(\n",
    "            LabelsToFlows(keys=\"label\", flow_key=\"flow\")\n",
    "        )  # finally create new key \"flows\" with 3 channels 1) foreground 2) dx flow 3) dy flow\n",
    "\n",
    "        return train_xforms\n",
    "\n",
    "    def get_val_preprocessing(self):\n",
    "        val_xforms = []\n",
    "        val_xforms.append(LoadTiffd(keys=[\"image\", \"label\"], allow_missing_keys=True))\n",
    "        val_xforms.append(\n",
    "            mt.EnsureTyped(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                data_type=\"tensor\",\n",
    "                dtype=torch.float,\n",
    "                allow_missing_keys=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if self.config(\"prescale\", True):\n",
    "            print(\"Prescaling val images to 0..1\")\n",
    "            val_xforms.append(\n",
    "                mt.ScaleIntensityd(keys=\"image\", minv=0, maxv=1, channel_wise=True)\n",
    "            )\n",
    "\n",
    "        val_xforms.append(\n",
    "            mt.ScaleIntensityRangePercentilesd(\n",
    "                keys=\"image\",\n",
    "                lower=1,\n",
    "                upper=99,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                channel_wise=True,\n",
    "                clip=True,\n",
    "            )\n",
    "        )\n",
    "        val_xforms.append(\n",
    "            LabelsToFlows(keys=\"label\", flow_key=\"flow\", allow_missing_keys=True)\n",
    "        )\n",
    "\n",
    "        return val_xforms\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        train_dataset_data = self.config(\"train#dataset#data\")\n",
    "        if isinstance(train_dataset_data, list):  # FIXME, why check\n",
    "            train_files = train_dataset_data\n",
    "        else:\n",
    "            train_files, _ = self.train_dataset_data\n",
    "        logger.info(f\"train files {len(train_files)}\")\n",
    "        return Dataset(data=train_files, transform=mt.Compose(self.train_preprocessing))\n",
    "\n",
    "    def get_val_dataset(self):\n",
    "        \"\"\"this is to be used for validation during training\"\"\"\n",
    "        val_dataset_data = self.config(\"validate#dataset#data\")\n",
    "        if isinstance(val_dataset_data, list):  # FIXME, why check\n",
    "            valid_files = val_dataset_data\n",
    "        else:\n",
    "            _, valid_files = self.train_dataset_data\n",
    "        return Dataset(data=valid_files, transform=mt.Compose(self.val_preprocessing))\n",
    "\n",
    "    def set_val_datalist(self, datalist_py):\n",
    "        self.parser[\"validate#dataset#data\"] = datalist_py\n",
    "        self._props.pop(\"val_loader\", None)\n",
    "        self._props.pop(\"val_dataset\", None)\n",
    "        self._props.pop(\"val_sampler\", None)\n",
    "\n",
    "    def get_train_sampler(self):\n",
    "        if self.config(\"use_weighted_sampler\", False):\n",
    "            data = self.train_dataset.data\n",
    "            logger.info(f\"Using weighted sampler, first item {data[0]}\")\n",
    "            sample_weights = 1.0 / torch.as_tensor(\n",
    "                [item.get(\"datalist_count\", 1.0) for item in data], dtype=torch.float\n",
    "            )  # inverse proportional to sub-datalist count\n",
    "            # if we are using weighed sampling, the number of iterations epoch must be provided\n",
    "            # (cant use a dataset length anymore)\n",
    "            num_samples_per_epoch = self.config(\"num_samples_per_epoch\", None)\n",
    "            if num_samples_per_epoch is None:\n",
    "                num_samples_per_epoch = len(data)  # a workaround if not provided\n",
    "                logger.warning(\n",
    "                    \"We are using weighted random sampler, but num_samples_per_epoch is not provided, \"\n",
    "                    f\"so using {num_samples_per_epoch} full data length as a workaround!\"\n",
    "                )\n",
    "\n",
    "            if self.is_distributed:\n",
    "                return DistributedWeightedSampler(\n",
    "                    self.train_dataset,\n",
    "                    shuffle=True,\n",
    "                    weights=sample_weights,\n",
    "                    num_samples=num_samples_per_epoch,\n",
    "                )  # custom implementation, as Pytorch does not have one\n",
    "            return WeightedRandomSampler(\n",
    "                weights=sample_weights, num_samples=num_samples_per_epoch\n",
    "            )\n",
    "\n",
    "        if self.is_distributed:\n",
    "            return DistributedSampler(self.train_dataset, shuffle=True)\n",
    "        return None\n",
    "\n",
    "    def get_val_sampler(self):\n",
    "        if self.is_distributed:\n",
    "            return DistributedSampler(self.val_dataset, shuffle=False)\n",
    "        return None\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        sampler = self.train_sampler\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config(\"train#batch_size\"),\n",
    "            shuffle=(sampler is None),\n",
    "            sampler=sampler,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.config(\"train#num_workers\"),\n",
    "        )\n",
    "\n",
    "    def get_val_loader(self):\n",
    "        sampler = self.val_sampler\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config(\"validate#batch_size\"),\n",
    "            shuffle=False,\n",
    "            sampler=sampler,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.config(\"validate#num_workers\"),\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        config = self.config\n",
    "        distributed = self.is_distributed\n",
    "        sliding_inferrer = config(\"inferer#sliding_inferer\")\n",
    "        use_amp = config(\"amp\")\n",
    "\n",
    "        amp_dtype = {\n",
    "            \"float32\": torch.float32,\n",
    "            \"bfloat16\": torch.bfloat16,\n",
    "            \"float16\": torch.float16,\n",
    "        }[config(\"amp_dtype\")]\n",
    "        if amp_dtype == torch.bfloat16 and not torch.cuda.is_bf16_supported():\n",
    "            amp_dtype = torch.float16\n",
    "            logger.warning(\n",
    "                \"bfloat16 dtype is not support on your device, changing to float16, use  --amp_dtype=float16 to set manually\"\n",
    "            )\n",
    "\n",
    "        use_gradscaler = use_amp and amp_dtype == torch.float16\n",
    "        logger.info(\n",
    "            f\"Using grad scaler {use_gradscaler} amp_dtype {amp_dtype} use_amp {use_amp}\"\n",
    "        )\n",
    "        grad_scaler = GradScaler(\n",
    "            enabled=use_gradscaler\n",
    "        )  # using GradScaler only for AMP float16 (not bfloat16)\n",
    "\n",
    "        loss_function = config(\"loss_function\")\n",
    "        acc_function = config(\"key_metric\")\n",
    "\n",
    "        ckpt_path = config(\"ckpt_path\")\n",
    "        channels_last = config(\"channels_last\")\n",
    "\n",
    "        num_epochs_per_saving = config(\"train#trainer#num_epochs_per_saving\")\n",
    "        num_epochs_per_validation = config(\"train#trainer#num_epochs_per_validation\")\n",
    "        num_epochs = config(\"train#trainer#max_epochs\")\n",
    "        val_schedule_list = self.schedule_validation_epochs(\n",
    "            num_epochs=num_epochs, num_epochs_per_validation=num_epochs_per_validation\n",
    "        )\n",
    "        logger.info(f\"Scheduling validation loops at epochs: {val_schedule_list}\")\n",
    "\n",
    "        train_loader = self.train_loader\n",
    "        val_loader = self.val_loader\n",
    "        optimizer = config(\"optimizer\")\n",
    "        model = self.network\n",
    "\n",
    "        tb_writer = None\n",
    "        csv_path = progress_path = None\n",
    "\n",
    "        if self.global_rank == 0 and ckpt_path is not None:\n",
    "            # rank 0 is responsible for heavy lifting of logging/saving\n",
    "            progress_path = os.path.join(ckpt_path, \"progress.yaml\")\n",
    "\n",
    "            tb_writer = SummaryWriter(log_dir=ckpt_path)\n",
    "            logger.info(f\"Writing Tensorboard logs to {tb_writer.log_dir}\")\n",
    "\n",
    "            if mlflow_is_imported:\n",
    "                if config(\"mlflow_tracking_uri\", None) is not None:\n",
    "                    mlflow.set_tracking_uri(config(\"mlflow_tracking_uri\"))\n",
    "                    mlflow.set_experiment(\"vista2d\")\n",
    "\n",
    "                    mlflow_run_name = config(\n",
    "                        \"mlflow_run_name\", f'vista2d train fold{config(\"fold\")}'\n",
    "                    )\n",
    "                    mlflow.start_run(\n",
    "                        run_name=mlflow_run_name,\n",
    "                        log_system_metrics=config(\"mlflow_log_system_metrics\", False),\n",
    "                    )\n",
    "                    mlflow.log_params(self.parser.config)\n",
    "                    mlflow.log_dict(\n",
    "                        self.parser.config, \"hyper_parameters.yaml\"\n",
    "                    )  # experimental\n",
    "\n",
    "            csv_path = os.path.join(ckpt_path, \"accuracy_history.csv\")\n",
    "            self.save_history_csv(\n",
    "                csv_path=csv_path,\n",
    "                header=[\n",
    "                    \"epoch\",\n",
    "                    \"metric\",\n",
    "                    \"loss\",\n",
    "                    \"iter\",\n",
    "                    \"time\",\n",
    "                    \"train_time\",\n",
    "                    \"validation_time\",\n",
    "                    \"epoch_time\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "        do_torch_save = (\n",
    "            (self.global_rank == 0)\n",
    "            and ckpt_path\n",
    "            and config(\"ckpt_save\")\n",
    "            and not config(\"train#skip\", False)\n",
    "        )\n",
    "        best_ckpt_path = os.path.join(ckpt_path, \"model.pt\")\n",
    "        intermediate_ckpt_path = os.path.join(ckpt_path, \"model_final.pt\")\n",
    "\n",
    "        best_metric = float(config(\"best_metric\", -1))\n",
    "        start_epoch = config(\"start_epoch\", 0)\n",
    "        best_metric_epoch = -1\n",
    "        pre_loop_time = time.time()\n",
    "        report_num_epochs = num_epochs\n",
    "        train_time = validation_time = 0\n",
    "        val_acc_history = []\n",
    "\n",
    "        if start_epoch > 0:\n",
    "            val_schedule_list = [v for v in val_schedule_list if v >= start_epoch]\n",
    "            if len(val_schedule_list) == 0:\n",
    "                val_schedule_list = [start_epoch]\n",
    "            print(f\"adjusted schedule_list {val_schedule_list}\")\n",
    "\n",
    "        logger.info(\n",
    "            f\"Using num_epochs => {num_epochs}\\n \"\n",
    "            f\"Using start_epoch => {start_epoch}\\n \"\n",
    "            f\"batch_size => {config('train#batch_size')} \\n \"\n",
    "            f\"num_warmup_epochs => {config('train#trainer#num_warmup_epochs')} \\n \"\n",
    "        )\n",
    "\n",
    "        lr_scheduler = config(\"lr_scheduler\")\n",
    "        if lr_scheduler is not None and start_epoch > 0:\n",
    "            lr_scheduler.last_epoch = start_epoch\n",
    "\n",
    "        range_num_epochs = range(start_epoch, num_epochs)\n",
    "\n",
    "        if distributed:\n",
    "            dist.barrier()\n",
    "\n",
    "        if (\n",
    "            self.global_rank == 0\n",
    "            and tb_writer is not None\n",
    "            and mlflow_is_imported\n",
    "            and mlflow.is_tracking_uri_set()\n",
    "        ):\n",
    "            mlflow.log_param(\"len_train_set\", len(train_loader.dataset))\n",
    "            mlflow.log_param(\"len_val_set\", len(val_loader.dataset))\n",
    "\n",
    "        for epoch in range_num_epochs:\n",
    "            report_epoch = epoch\n",
    "\n",
    "            if distributed:\n",
    "                if isinstance(train_loader.sampler, DistributedSampler):\n",
    "                    train_loader.sampler.set_epoch(epoch)\n",
    "                dist.barrier()\n",
    "\n",
    "            epoch_time = start_time = time.time()\n",
    "\n",
    "            train_loss, train_acc = 0, 0\n",
    "\n",
    "            if not config(\"train#skip\", False):\n",
    "                train_loss, train_acc = self.train_epoch(\n",
    "                    model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_function=loss_function,\n",
    "                    acc_function=acc_function,\n",
    "                    grad_scaler=grad_scaler,\n",
    "                    epoch=report_epoch,\n",
    "                    rank=self.rank,\n",
    "                    global_rank=self.global_rank,\n",
    "                    num_epochs=report_num_epochs,\n",
    "                    use_amp=use_amp,\n",
    "                    amp_dtype=amp_dtype,\n",
    "                    channels_last=channels_last,\n",
    "                    device=config(\"device\"),\n",
    "                )\n",
    "\n",
    "            train_time = time.time() - start_time\n",
    "            logger.info(\n",
    "                f\"Latest training  {report_epoch}/{report_num_epochs - 1} \"\n",
    "                f\"loss: {train_loss:.4f} time {train_time:.2f}s  \"\n",
    "                f\"lr: {optimizer.param_groups[0]['lr']:.4e}\"\n",
    "            )\n",
    "\n",
    "            if self.global_rank == 0 and tb_writer is not None:\n",
    "                tb_writer.add_scalar(\"train/loss\", train_loss, report_epoch)\n",
    "\n",
    "                if mlflow_is_imported and mlflow.is_tracking_uri_set():\n",
    "                    mlflow.log_metric(\"train/loss\", train_loss, step=report_epoch)\n",
    "                    mlflow.log_metric(\"train/epoch_time\", train_time, step=report_epoch)\n",
    "\n",
    "            # validate every num_epochs_per_validation epochs (defaults to 1, every epoch)\n",
    "            val_acc_mean = -1\n",
    "            if (\n",
    "                len(val_schedule_list) > 0\n",
    "                and epoch + 1 >= val_schedule_list[0]\n",
    "                and val_loader is not None\n",
    "                and len(val_loader) > 0\n",
    "            ):\n",
    "                val_schedule_list.pop(0)\n",
    "\n",
    "                start_time = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                val_loss, val_acc = self.val_epoch(\n",
    "                    model=model,\n",
    "                    val_loader=val_loader,\n",
    "                    sliding_inferrer=sliding_inferrer,\n",
    "                    loss_function=loss_function,\n",
    "                    acc_function=acc_function,\n",
    "                    epoch=report_epoch,\n",
    "                    rank=self.rank,\n",
    "                    global_rank=self.global_rank,\n",
    "                    num_epochs=report_num_epochs,\n",
    "                    use_amp=use_amp,\n",
    "                    amp_dtype=amp_dtype,\n",
    "                    channels_last=channels_last,\n",
    "                    device=config(\"device\"),\n",
    "                )\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                validation_time = time.time() - start_time\n",
    "\n",
    "                val_acc_mean = float(np.mean(val_acc))\n",
    "                val_acc_history.append((report_epoch, val_acc_mean))\n",
    "\n",
    "                if self.global_rank == 0:\n",
    "                    logger.info(\n",
    "                        f\"Latest validation {report_epoch}/{report_num_epochs - 1} \"\n",
    "                        f\"loss: {val_loss:.4f} acc_avg: {val_acc_mean:.4f} acc: {val_acc} time: {validation_time:.2f}s\"\n",
    "                    )\n",
    "\n",
    "                    if tb_writer is not None:\n",
    "                        tb_writer.add_scalar(\"val/acc\", val_acc_mean, report_epoch)\n",
    "                        tb_writer.add_scalar(\"val/loss\", val_loss, report_epoch)\n",
    "                        if mlflow_is_imported and mlflow.is_tracking_uri_set():\n",
    "                            mlflow.log_metric(\n",
    "                                \"val/acc\", val_acc_mean, step=report_epoch\n",
    "                            )\n",
    "                            mlflow.log_metric(\n",
    "                                \"val/epoch_time\", validation_time, step=report_epoch\n",
    "                            )\n",
    "\n",
    "                    timing_dict = {\n",
    "                        \"time\": f\"{(time.time() - pre_loop_time) / 3600:.2f} hr\",\n",
    "                        \"train_time\": f\"{train_time:.2f}s\",\n",
    "                        \"validation_time\": f\"{validation_time:.2f}s\",\n",
    "                        \"epoch_time\": f\"{time.time() - epoch_time:.2f}s\",\n",
    "                    }\n",
    "\n",
    "                    if val_acc_mean > best_metric:\n",
    "                        logger.info(\n",
    "                            f\"New best metric ({best_metric:.6f} --> {val_acc_mean:.6f}). \"\n",
    "                        )\n",
    "                        best_metric, best_metric_epoch = val_acc_mean, report_epoch\n",
    "                        save_time = 0\n",
    "                        if do_torch_save:\n",
    "                            save_time = self.checkpoint_save(\n",
    "                                ckpt=best_ckpt_path,\n",
    "                                model=model,\n",
    "                                epoch=best_metric_epoch,\n",
    "                                best_metric=best_metric,\n",
    "                            )\n",
    "\n",
    "                        if progress_path is not None:\n",
    "                            self.save_progress_yaml(\n",
    "                                progress_path=progress_path,\n",
    "                                ckpt=best_ckpt_path if do_torch_save else None,\n",
    "                                best_avg_score_epoch=best_metric_epoch,\n",
    "                                best_avg_score=best_metric,\n",
    "                                save_time=save_time,\n",
    "                                **timing_dict,\n",
    "                            )\n",
    "                    if csv_path is not None:\n",
    "                        self.save_history_csv(\n",
    "                            csv_path=csv_path,\n",
    "                            epoch=report_epoch,\n",
    "                            metric=f\"{val_acc_mean:.4f}\",\n",
    "                            loss=f\"{train_loss:.4f}\",\n",
    "                            iter=report_epoch * len(train_loader.dataset),\n",
    "                            **timing_dict,\n",
    "                        )\n",
    "\n",
    "                # sanity check\n",
    "                if (\n",
    "                    epoch > max(20, num_epochs / 4)\n",
    "                    and 0 <= val_acc_mean < 0.01\n",
    "                    and config(\"stop_on_lowacc\", True)\n",
    "                ):\n",
    "                    logger.info(\n",
    "                        f\"Accuracy seems very low at epoch {report_epoch}, acc {val_acc_mean}. \"\n",
    "                        \"Most likely optimization diverged, try setting a smaller learning_rate\"\n",
    "                        f\" than {config('learning_rate')}\"\n",
    "                    )\n",
    "                    raise ValueError(\n",
    "                        f\"Accuracy seems very low at epoch {report_epoch}, acc {val_acc_mean}. \"\n",
    "                        \"Most likely optimization diverged, try setting a smaller learning_rate\"\n",
    "                        f\" than {config('learning_rate')}\"\n",
    "                    )\n",
    "\n",
    "            # save intermediate checkpoint every num_epochs_per_saving epochs\n",
    "            if do_torch_save and (\n",
    "                (epoch + 1) % num_epochs_per_saving == 0 or (epoch + 1) >= num_epochs\n",
    "            ):\n",
    "                if report_epoch != best_metric_epoch:\n",
    "                    self.checkpoint_save(\n",
    "                        ckpt=intermediate_ckpt_path,\n",
    "                        model=model,\n",
    "                        epoch=report_epoch,\n",
    "                        best_metric=val_acc_mean,\n",
    "                    )\n",
    "                else:\n",
    "                    try:\n",
    "                        shutil.copyfile(\n",
    "                            best_ckpt_path, intermediate_ckpt_path\n",
    "                        )  # if already saved once\n",
    "                    except Exception as err:\n",
    "                        logger.warning(\n",
    "                            f\"error copying {best_ckpt_path} {intermediate_ckpt_path} {err}\"\n",
    "                        )\n",
    "                        pass\n",
    "\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            if self.global_rank == 0:\n",
    "                # report time estimate\n",
    "                time_remaining_estimate = train_time * (num_epochs - epoch)\n",
    "                if val_loader is not None and len(val_loader) > 0:\n",
    "                    if validation_time == 0:\n",
    "                        validation_time = train_time\n",
    "                    time_remaining_estimate += validation_time * len(val_schedule_list)\n",
    "\n",
    "                logger.info(\n",
    "                    f\"Estimated remaining training time for the current model fold {config('fold')} is \"\n",
    "                    f\"{time_remaining_estimate/3600:.2f} hr, \"\n",
    "                    f\"running time {(time.time() - pre_loop_time)/3600:.2f} hr, \"\n",
    "                    f\"est total time {(time.time() - pre_loop_time + time_remaining_estimate)/3600:.2f} hr \\n\"\n",
    "                )\n",
    "\n",
    "        # end of main epoch loop\n",
    "        train_loader = val_loader = optimizer = None\n",
    "\n",
    "        # optionally validate best checkpoint\n",
    "        logger.info(f\"Checking to run final testing {config('run_final_testing')}\")\n",
    "        if config(\"run_final_testing\"):\n",
    "            if distributed:\n",
    "                dist.barrier()\n",
    "            _ckpt_name = (\n",
    "                best_ckpt_path\n",
    "                if os.path.exists(best_ckpt_path)\n",
    "                else intermediate_ckpt_path\n",
    "            )\n",
    "            if not os.path.exists(_ckpt_name):\n",
    "                logger.info(\n",
    "                    f\"Unable to validate final no checkpoints found {best_ckpt_path}, {intermediate_ckpt_path}\"\n",
    "                )\n",
    "            else:\n",
    "                # self._props.pop(\"network\", None)\n",
    "                # self._set_props.pop(\"network\", None)\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                best_metric = self.run_final_testing(\n",
    "                    pretrained_ckpt_path=_ckpt_name,\n",
    "                    progress_path=progress_path,\n",
    "                    best_metric_epoch=best_metric_epoch,\n",
    "                    pre_loop_time=pre_loop_time,\n",
    "                )\n",
    "\n",
    "                if (\n",
    "                    self.global_rank == 0\n",
    "                    and tb_writer is not None\n",
    "                    and mlflow_is_imported\n",
    "                    and mlflow.is_tracking_uri_set()\n",
    "                ):\n",
    "                    mlflow.log_param(\"acc_testing\", val_acc_mean)\n",
    "                    mlflow.log_metric(\"acc_testing\", val_acc_mean)\n",
    "\n",
    "        if tb_writer is not None:\n",
    "            tb_writer.flush()\n",
    "            tb_writer.close()\n",
    "\n",
    "            if mlflow_is_imported and mlflow.is_tracking_uri_set():\n",
    "                mlflow.end_run()\n",
    "\n",
    "        logger.info(\n",
    "            f\"=== DONE: best_metric: {best_metric:.4f} at epoch: {best_metric_epoch} of {report_num_epochs}.\"\n",
    "            f\"Training time {(time.time() - pre_loop_time)/3600:.2f} hr.\"\n",
    "        )\n",
    "        return best_metric\n",
    "\n",
    "    def run_final_testing(\n",
    "        self, pretrained_ckpt_path, progress_path, best_metric_epoch, pre_loop_time\n",
    "    ):\n",
    "        logger.info(\"Running final best model testing set!\")\n",
    "\n",
    "        # validate\n",
    "        start_time = time.time()\n",
    "\n",
    "        self._props.pop(\"network\", None)\n",
    "        self.parser[\"pretrained_ckpt_path\"] = pretrained_ckpt_path\n",
    "        self.parser[\"validate#evaluator#postprocessing\"] = None  # not saving images\n",
    "\n",
    "        val_acc_mean, val_loss, val_acc = self.validate(val_key=\"testing\")\n",
    "        validation_time = f\"{time.time() - start_time:.2f}s\"\n",
    "        val_acc_mean = float(np.mean(val_acc))\n",
    "        logger.info(\n",
    "            f\"Testing: loss: {val_loss:.4f} acc_avg: {val_acc_mean:.4f} acc {val_acc} time {validation_time}\"\n",
    "        )\n",
    "\n",
    "        if self.global_rank == 0 and progress_path is not None:\n",
    "            self.save_progress_yaml(\n",
    "                progress_path=progress_path,\n",
    "                ckpt=pretrained_ckpt_path,\n",
    "                best_avg_score_epoch=best_metric_epoch,\n",
    "                best_avg_score=val_acc_mean,\n",
    "                validation_time=validation_time,\n",
    "                run_final_testing=True,\n",
    "                time=f\"{(time.time() - pre_loop_time) / 3600:.2f} hr\",\n",
    "            )\n",
    "        return val_acc_mean\n",
    "\n",
    "    def validate(self, validation_files=None, val_key=None, datalist=None):\n",
    "        if (\n",
    "            self.config(\"pretrained_ckpt_name\", None) is None\n",
    "            and self.config(\"pretrained_ckpt_path\", None) is None\n",
    "        ):\n",
    "            self.parser[\"pretrained_ckpt_name\"] = \"model.pt\"\n",
    "            logger.info(\"Using default model.pt checkpoint for validation.\")\n",
    "\n",
    "        grouping = self.config(\n",
    "            \"validate#grouping\", False\n",
    "        )  # whether to computer average per datalist\n",
    "        if validation_files is None:\n",
    "            validation_files = self.read_val_datalists(\n",
    "                \"validate\", datalist, val_key=val_key, merge=not grouping\n",
    "            )\n",
    "        if len(validation_files) == 0:\n",
    "            logger.warning(f\"No validation files found {datalist} {val_key}!\")\n",
    "            return 0, 0, 0\n",
    "        if not grouping or not isinstance(validation_files[0], (list, tuple)):\n",
    "            validation_files = [validation_files]\n",
    "        logger.info(\n",
    "            f\"validation file groups {len(validation_files)} grouping {grouping}\"\n",
    "        )\n",
    "        val_acc_dict = {}\n",
    "\n",
    "        amp_dtype = {\n",
    "            \"float32\": torch.float32,\n",
    "            \"bfloat16\": torch.bfloat16,\n",
    "            \"float16\": torch.float16,\n",
    "        }[self.config(\"amp_dtype\")]\n",
    "        if amp_dtype == torch.bfloat16 and not torch.cuda.is_bf16_supported():\n",
    "            amp_dtype = torch.float16\n",
    "            logger.warning(\n",
    "                \"bfloat16 dtype is not support on your device, changing to float16, use  --amp_dtype=float16 to set manually\"\n",
    "            )\n",
    "\n",
    "        for datalist_id, group_files in enumerate(validation_files):\n",
    "            self.set_val_datalist(group_files)\n",
    "            val_loader = self.val_loader\n",
    "\n",
    "            start_time = time.time()\n",
    "            val_loss, val_acc = self.val_epoch(\n",
    "                model=self.network,\n",
    "                val_loader=val_loader,\n",
    "                sliding_inferrer=self.config(\"inferer#sliding_inferer\"),\n",
    "                loss_function=self.config(\"loss_function\"),\n",
    "                acc_function=self.config(\"key_metric\"),\n",
    "                rank=self.rank,\n",
    "                global_rank=self.global_rank,\n",
    "                use_amp=self.config(\"amp\"),\n",
    "                amp_dtype=amp_dtype,\n",
    "                post_transforms=self.config(\"validate#evaluator#postprocessing\"),\n",
    "                channels_last=self.config(\"channels_last\"),\n",
    "                device=self.config(\"device\"),\n",
    "            )\n",
    "            val_acc_mean = float(np.mean(val_acc))\n",
    "            logger.info(\n",
    "                f\"Validation {datalist_id} complete, loss_avg: {val_loss:.4f} \"\n",
    "                f\"acc_avg: {val_acc_mean:.4f} acc {val_acc} time {time.time() - start_time:.2f}s\"\n",
    "            )\n",
    "            val_acc_dict[datalist_id] = val_acc_mean\n",
    "        for k, v in val_acc_dict.items():\n",
    "            logger.info(f\"group: {k} => {v:.4f}\")\n",
    "        val_acc_mean = sum(val_acc_dict.values()) / len(val_acc_dict.values())\n",
    "        logger.info(f\"Testing group score average: {val_acc_mean:.4f}\")\n",
    "        return val_acc_mean, val_loss, val_acc\n",
    "\n",
    "    def infer(self, infer_files=None, infer_key=None, datalist=None):\n",
    "        if (\n",
    "            self.config(\"pretrained_ckpt_name\", None) is None\n",
    "            and self.config(\"pretrained_ckpt_path\", None) is None\n",
    "        ):\n",
    "            self.parser[\"pretrained_ckpt_name\"] = \"model.pt\"\n",
    "            logger.info(\"Using default model.pt checkpoint for inference.\")\n",
    "\n",
    "        if infer_files is None:\n",
    "            infer_files = self.read_val_datalists(\n",
    "                \"infer\", datalist, val_key=infer_key, merge=True\n",
    "            )\n",
    "        if len(infer_files) == 0:\n",
    "            logger.warning(f\"no file to infer {datalist} {infer_key}.\")\n",
    "            return\n",
    "        logger.info(f\"inference files {len(infer_files)}\")\n",
    "        self.set_val_datalist(infer_files)\n",
    "        val_loader = self.val_loader\n",
    "\n",
    "        amp_dtype = {\n",
    "            \"float32\": torch.float32,\n",
    "            \"bfloat16\": torch.bfloat16,\n",
    "            \"float16\": torch.float16,\n",
    "        }[self.config(\"amp_dtype\")]\n",
    "        if amp_dtype == torch.bfloat16 and not torch.cuda.is_bf16_supported():\n",
    "            amp_dtype = torch.bfloat16\n",
    "            logger.warning(\n",
    "                \"bfloat16 dtype is not support on your device, changing to float16, use  --amp_dtype=float16 to set manually\"\n",
    "            )\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.val_epoch(\n",
    "            model=self.network,\n",
    "            val_loader=val_loader,\n",
    "            sliding_inferrer=self.config(\"inferer#sliding_inferer\"),\n",
    "            loss_function=None,\n",
    "            acc_function=None,\n",
    "            rank=self.rank,\n",
    "            global_rank=self.global_rank,\n",
    "            use_amp=self.config(\"amp\"),\n",
    "            amp_dtype=amp_dtype,\n",
    "            post_transforms=self.config(\"infer#evaluator#postprocessing\"),\n",
    "            channels_last=self.config(\"channels_last\"),\n",
    "            device=self.config(\"device\"),\n",
    "        )\n",
    "        logger.info(f\"Inference complete time {time.time() - start_time:.2f}s\")\n",
    "        return\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def val_epoch(\n",
    "        self,\n",
    "        model,\n",
    "        val_loader,\n",
    "        sliding_inferrer,\n",
    "        loss_function=None,\n",
    "        acc_function=None,\n",
    "        epoch=0,\n",
    "        rank=0,\n",
    "        global_rank=0,\n",
    "        num_epochs=0,\n",
    "        use_amp=True,\n",
    "        amp_dtype=torch.float16,\n",
    "        post_transforms=None,\n",
    "        channels_last=False,\n",
    "        device=None,\n",
    "    ):\n",
    "        model.eval()\n",
    "        distributed = dist.is_available() and dist.is_initialized()\n",
    "        memory_format = torch.channels_last if channels_last else torch.preserve_format\n",
    "\n",
    "        run_loss = CumulativeAverage()\n",
    "        run_acc = CumulativeAverage()\n",
    "        run_loss.append(torch.tensor(0, device=device), count=0)\n",
    "\n",
    "        avg_loss = avg_acc = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # In DDP, each replica has a subset of data, but if total data length is not evenly divisible by num_replicas,\n",
    "        # then some replicas has 1 extra repeated item.\n",
    "        # For proper validation with batch of 1, we only want to collect metrics for non-repeated items,\n",
    "        # hence let's compute a proper subset length\n",
    "        nonrepeated_data_length = len(val_loader.dataset)\n",
    "        sampler = val_loader.sampler\n",
    "        if (\n",
    "            distributed\n",
    "            and isinstance(sampler, DistributedSampler)\n",
    "            and not sampler.drop_last\n",
    "        ):\n",
    "            nonrepeated_data_length = len(\n",
    "                range(sampler.rank, len(sampler.dataset), sampler.num_replicas)\n",
    "            )\n",
    "\n",
    "        for idx, batch_data in enumerate(val_loader):\n",
    "            data = (\n",
    "                batch_data[\"image\"]\n",
    "                .as_subclass(torch.Tensor)\n",
    "                .to(memory_format=memory_format, device=device)\n",
    "            )\n",
    "            filename = batch_data[\"image\"].meta[ImageMetaKey.FILENAME_OR_OBJ]\n",
    "            batch_size = data.shape[0]\n",
    "            loss = acc = None\n",
    "\n",
    "            with autocast(enabled=use_amp, dtype=amp_dtype):\n",
    "                logits = sliding_inferrer(inputs=data, network=model)\n",
    "            data = None\n",
    "\n",
    "            # calc loss\n",
    "            if loss_function is not None:\n",
    "                target = (\n",
    "                    batch_data[\"flow\"]\n",
    "                    .as_subclass(torch.Tensor)\n",
    "                    .to(device=logits.device)\n",
    "                )\n",
    "                loss = loss_function(logits, target)\n",
    "                run_loss.append(loss.to(device=device), count=batch_size)\n",
    "                target = None\n",
    "\n",
    "            pred_mask_all = []\n",
    "\n",
    "            for b_ind in range(logits.shape[0]):  # go over batch dim\n",
    "                pred_mask, p = LogitsToLabels()(logits=logits[b_ind], filename=filename)\n",
    "                pred_mask_all.append(pred_mask)\n",
    "\n",
    "            if acc_function is not None:\n",
    "                label = batch_data[\"label\"].as_subclass(torch.Tensor)\n",
    "\n",
    "                for b_ind in range(label.shape[0]):\n",
    "                    acc = acc_function(pred_mask_all[b_ind], label[b_ind, 0].long())\n",
    "                    acc = (\n",
    "                        acc.detach().clone()\n",
    "                        if isinstance(acc, torch.Tensor)\n",
    "                        else torch.tensor(acc)\n",
    "                    )\n",
    "\n",
    "                    if idx < nonrepeated_data_length:\n",
    "                        run_acc.append(acc.to(device=device), count=1)\n",
    "                    else:\n",
    "                        run_acc.append(torch.zeros_like(acc, device=device), count=0)\n",
    "                label = None\n",
    "\n",
    "            avg_loss = loss.cpu() if loss is not None else 0\n",
    "            avg_acc = acc.cpu().numpy() if acc is not None else 0\n",
    "\n",
    "            logger.info(\n",
    "                f\"Val {epoch}/{num_epochs} {idx}/{len(val_loader)} \"\n",
    "                f\"loss: {avg_loss:.4f} acc {avg_acc}  time {time.time() - start_time:.2f}s\"\n",
    "            )\n",
    "\n",
    "            if post_transforms:\n",
    "                seg = torch.from_numpy(\n",
    "                    np.stack(pred_mask_all, axis=0).astype(np.int32)\n",
    "                ).unsqueeze(1)\n",
    "                batch_data[\"seg\"] = convert_to_dst_type(\n",
    "                    seg,\n",
    "                    batch_data[\"image\"],\n",
    "                    dtype=torch.int32,\n",
    "                    device=torch.device(\"cpu\"),\n",
    "                )[0]\n",
    "                for bd in decollate_batch(batch_data):\n",
    "                    post_transforms(bd)  # (currently only to save output mask)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "        label = target = data = batch_data = None\n",
    "\n",
    "        if distributed:\n",
    "            dist.barrier()\n",
    "\n",
    "        avg_loss = run_loss.aggregate()\n",
    "        avg_acc = run_acc.aggregate()\n",
    "\n",
    "        if np.any(avg_acc < 0):\n",
    "            dist.barrier()\n",
    "            logger.warning(\n",
    "                f\"Avg accuracy is negative ({avg_acc}), something went wrong!!!!!\"\n",
    "            )\n",
    "\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    def train_epoch(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        loss_function,\n",
    "        acc_function,\n",
    "        grad_scaler,\n",
    "        epoch,\n",
    "        rank,\n",
    "        global_rank=0,\n",
    "        num_epochs=0,\n",
    "        use_amp=True,\n",
    "        amp_dtype=torch.float16,\n",
    "        channels_last=False,\n",
    "        device=None,\n",
    "    ):\n",
    "        model.train()\n",
    "        memory_format = torch.channels_last if channels_last else torch.preserve_format\n",
    "\n",
    "        run_loss = CumulativeAverage()\n",
    "\n",
    "        start_time = time.time()\n",
    "        avg_loss = avg_acc = 0\n",
    "        for idx, batch_data in enumerate(train_loader):\n",
    "            data = (\n",
    "                batch_data[\"image\"]\n",
    "                .as_subclass(torch.Tensor)\n",
    "                .to(memory_format=memory_format, device=device)\n",
    "            )\n",
    "            target = (\n",
    "                batch_data[\"flow\"]\n",
    "                .as_subclass(torch.Tensor)\n",
    "                .to(memory_format=memory_format, device=device)\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(enabled=use_amp, dtype=amp_dtype):\n",
    "                logits = model(data)\n",
    "\n",
    "            # print('logits', logits.shape, logits.dtype)\n",
    "            loss = loss_function(logits.float(), target)\n",
    "\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "            batch_size = data.shape[0]\n",
    "\n",
    "            run_loss.append(loss, count=batch_size)\n",
    "            avg_loss = run_loss.aggregate()\n",
    "\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch}/{num_epochs} {idx}/{len(train_loader)} \"\n",
    "                f\"loss: {avg_loss:.4f} time {time.time() - start_time:.2f}s \"\n",
    "            )\n",
    "            start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        data = None\n",
    "        target = None\n",
    "        batch_data = None\n",
    "\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    def save_history_csv(self, csv_path=None, header=None, **kwargs):\n",
    "        if csv_path is not None:\n",
    "            if header is not None:\n",
    "                with open(csv_path, \"a\") as myfile:\n",
    "                    wrtr = csv.writer(myfile, delimiter=\"\\t\")\n",
    "                    wrtr.writerow(header)\n",
    "            if len(kwargs):\n",
    "                with open(csv_path, \"a\") as myfile:\n",
    "                    wrtr = csv.writer(myfile, delimiter=\"\\t\")\n",
    "                    wrtr.writerow(list(kwargs.values()))\n",
    "\n",
    "    def save_progress_yaml(self, progress_path=None, ckpt=None, **report):\n",
    "        if ckpt is not None:\n",
    "            report[\"model\"] = ckpt\n",
    "\n",
    "        report[\"date\"] = str(datetime.now())[:19]\n",
    "\n",
    "        if progress_path is not None:\n",
    "            yaml.add_representer(\n",
    "                float,\n",
    "                lambda dumper, value: dumper.represent_scalar(\n",
    "                    \"tag:yaml.org,2002:float\", f\"{value:.4f}\"\n",
    "                ),\n",
    "            )\n",
    "            with open(progress_path, \"a\") as progress_file:\n",
    "                yaml.dump(\n",
    "                    [report],\n",
    "                    stream=progress_file,\n",
    "                    allow_unicode=True,\n",
    "                    default_flow_style=None,\n",
    "                    sort_keys=False,\n",
    "                )\n",
    "\n",
    "        logger.info(\"Progress:\" + \",\".join(f\" {k}: {v}\" for k, v in report.items()))\n",
    "\n",
    "    def checkpoint_save(self, ckpt: str, model: torch.nn.Module, **kwargs):\n",
    "        # save checkpoint and config\n",
    "        save_time = time.time()\n",
    "        if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "            state_dict = model.module.state_dict()\n",
    "        else:\n",
    "            state_dict = model.state_dict()\n",
    "\n",
    "        if self.config(\"compile\", False):\n",
    "            # remove key prefix of compiled models\n",
    "            state_dict = OrderedDict(\n",
    "                (k[len(\"_orig_mod.\") :] if k.startswith(\"_orig_mod.\") else k, v)\n",
    "                for k, v in state_dict.items()\n",
    "            )\n",
    "\n",
    "        torch.save(\n",
    "            {\"state_dict\": state_dict, \"config\": self.parser.config, **kwargs}, ckpt\n",
    "        )\n",
    "\n",
    "        save_time = time.time() - save_time\n",
    "        logger.info(\n",
    "            f\"Saving checkpoint process: {ckpt}, {kwargs}, save_time {save_time:.2f}s\"\n",
    "        )\n",
    "\n",
    "        return save_time\n",
    "\n",
    "    def checkpoint_load(self, ckpt: str, model: torch.nn.Module, **kwargs):\n",
    "        # load checkpoint\n",
    "        if not os.path.isfile(ckpt):\n",
    "            logger.warning(\"Invalid checkpoint file: \" + str(ckpt))\n",
    "            return\n",
    "        checkpoint = torch.load(ckpt, map_location=\"cpu\")\n",
    "\n",
    "        # if self.config(\"compile\", False):\n",
    "        #     checkpoint[\"state_dict\"] = OrderedDict((k[len(\"_orig_mod.\"):] if k.startswith(\"_orig_mod.\") else k, v) for k, v in checkpoint[\"state_dict\"].items())\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"], strict=True)\n",
    "        epoch = checkpoint.get(\"epoch\", 0)\n",
    "        best_metric = checkpoint.get(\"best_metric\", 0)\n",
    "\n",
    "        if self.config(\"continue\", False):\n",
    "            if \"epoch\" in checkpoint:\n",
    "                self.parser[\"start_epoch\"] = checkpoint[\"epoch\"]\n",
    "            if \"best_metric\" in checkpoint:\n",
    "                self.parser[\"best_metric\"] = checkpoint[\"best_metric\"]\n",
    "\n",
    "        logger.info(\n",
    "            f\"=> loaded checkpoint {ckpt} (epoch {epoch}) \"\n",
    "            f\"(best_metric {best_metric}) setting start_epoch {self.config('start_epoch')}\"\n",
    "        )\n",
    "        self.parser[\"start_epoch\"] = int(self.config(\"start_epoch\")) + 1\n",
    "        return\n",
    "\n",
    "    def schedule_validation_epochs(\n",
    "        self, num_epochs, num_epochs_per_validation=None, fraction=0.16\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Schedule of epochs to validate (progressively more frequently)\n",
    "            num_epochs - total number of epochs\n",
    "            num_epochs_per_validation - if provided use a linear schedule with this step\n",
    "            init_step\n",
    "        \"\"\"\n",
    "\n",
    "        if num_epochs_per_validation is None:\n",
    "            x = (\n",
    "                np.sin(np.linspace(0, np.pi / 2, max(10, int(fraction * num_epochs))))\n",
    "                * num_epochs\n",
    "            ).astype(int)\n",
    "            x = np.cumsum(np.sort(np.diff(np.unique(x)))[::-1])\n",
    "            x[-1] = num_epochs\n",
    "            x = x.tolist()\n",
    "        else:\n",
    "            if num_epochs_per_validation >= num_epochs:\n",
    "                x = [num_epochs_per_validation]\n",
    "            else:\n",
    "                x = list(\n",
    "                    range(\n",
    "                        num_epochs_per_validation, num_epochs, num_epochs_per_validation\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        if len(x) == 0:\n",
    "            x = [0]\n",
    "\n",
    "        return x\n",
    "\n",
    "   # to be able to run directly as python scripts/workflow.py --config_file=...\n",
    "    # for debugging and development\n",
    "\n",
    "sys.path.append(str(Path(__file__).parent.parent))\n",
    "\n",
    "workflow = VistaCell(**kwargs)\n",
    "workflow.initialize()\n",
    "workflow.run()\n",
    "workflow.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce2967-8660-4a47-81f3-86c4025b8d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
